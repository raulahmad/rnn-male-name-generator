{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation: Male Names Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this Notebook is to build a small, simple **Recurrent Neural Network** to illustrate how text generation works, and how to implement it with TensorFlow. \n",
    "\n",
    "We are building a male name generator. For the sake of the example, we have also **manually implemented** all kinds of word **encoding** and decoding needed, even one-hot encoding.\n",
    "\n",
    "The data used in this notebook has been obtained from Spain's National Statistics Institute, and it corresponds to **males with spanish citizenship**. For privacy reasons, the frecuency of the name must be at least 20 for it to appear on the list. Data can be found here https://www.ine.es/tnombres/formGeneral.do\n",
    "\n",
    "Let's begin with some initial settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SimpleRNN, TimeDistributed, Dense, Masking\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths and filenames\n",
    "DATA_PATH = '../data'\n",
    "OUTPUT_PATH = '../output'\n",
    "MALE_NAMES_FILEPATH = '../data/male_names.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Remark:* for the sake of better understanding, depending on the context, we will use the terms *character* and *letter* indistinctly.\n",
    "\n",
    "We are going to use one of the most basic RNN, the **Elman Network**. We are going to train the network to predict the current letter given the previous letters. An Elman Network considers the previous inputs for computing the next output, but it does not consider future inputs.\n",
    "\n",
    "The idea behind a text generator with this network is that, at every timestep, for each word in the dictionary, we compute its **probability** to appear conditioned to to the fact that we already have some previous inputs. \n",
    "\n",
    "First, we need to **encode** our inputs so we can feed them to the network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to map every character of the alphabet to an integer. Here we create mappings **map_char_to_int** and **map_int_to_char**, which map a character to its integer representation and viceversa. We will also map the **dot** (.), which is not part of any name, but will indicate our **EOF** (End of File); and a **space**, since some names consist of two words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard latin alphabet\n",
    "standard_chars = [chr(i) for i in range(97, 123)]\n",
    "# Special characters for languages spoken in Spain, the dot, and the space\n",
    "special_chars = ['à', 'á', 'è', 'é', 'í', 'ò', 'ó', 'ú', 'ñ', 'ç', \"'\", '.', ' ']\n",
    "\n",
    "chars = standard_chars + special_chars\n",
    "\n",
    "seq = [i for i in range(len(chars))]\n",
    "map_char_to_int = dict(zip(chars, seq))\n",
    "map_int_to_char = dict(zip(seq, chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of characters to integers:\n",
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, 'à': 26, 'á': 27, 'è': 28, 'é': 29, 'í': 30, 'ò': 31, 'ó': 32, 'ú': 33, 'ñ': 34, 'ç': 35, \"'\": 36, '.': 37, ' ': 38}\n"
     ]
    }
   ],
   "source": [
    "print(\"Mapping of characters to integers:\")\n",
    "print(map_char_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary functions for mapping\n",
    "We are going to define some useful functions. We are going to use the following convention:\n",
    "* Variables ending with `_int` will represent *something* mapped to its integer form.\n",
    "* Variables ending with `_encoded` will represent *something* one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(word_int, features):\n",
    "    '''\n",
    "    word_int -- array of integers, shape (k,)\n",
    "    features -- size of vocabulary\n",
    "    returns -> array with integers one-hot encoded, shape (k, features)\n",
    "    '''\n",
    "    k = len(word_int)\n",
    "    word_encoded = np.zeros((k, features), dtype = 'int8')\n",
    "    for i in range(k):\n",
    "        pos = word_int[i]\n",
    "        word_encoded[i, pos] = 1\n",
    "    return word_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_decoding(word_encoded):\n",
    "    '''\n",
    "    word_encoded -- array of shape (k, features)\n",
    "    returns -> array of shape (k,)\n",
    "    '''\n",
    "    a, b = word_encoded.shape\n",
    "    word_int = np.zeros(a, dtype = 'int32')\n",
    "    for i in range(a):\n",
    "        pos = np.argmax(word_encoded[i])\n",
    "        word_int[i] = pos\n",
    "    return word_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_word_to_int(word, mapping):\n",
    "    '''\n",
    "    word -- string\n",
    "    mapping -- dictionary with characters as keys and integers as values\n",
    "    returns -> array with integers, shape (k,), where k is the length of the word'''\n",
    "    k = len(word)\n",
    "    word_int = np.zeros(k, dtype = 'int32')\n",
    "    for i, c in enumerate(word):\n",
    "        word_int[i] = mapping[c]\n",
    "    return word_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_int_to_word(word_int, mapping):\n",
    "    '''\n",
    "    word_int -- array with integers, shape (k,)\n",
    "    mapping -- dictionary with integers as keys and characters as values\n",
    "    returns -> string of length k\n",
    "    '''\n",
    "    word = ''\n",
    "    for i in word_int:\n",
    "        if i in mapping.keys():\n",
    "            word += mapping[i]\n",
    "        else:\n",
    "            word += 'UNK'\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_list(array, mapping):\n",
    "    '''\n",
    "    array -- list of words\n",
    "    mapping -- dictionary with characters as keys and integers as values\n",
    "    returns -> list of word_encoded elements, each of one has shape (k, n), k being the length of each word'''\n",
    "    result = []\n",
    "    for word in array:\n",
    "        word_int = encode_word_to_int(word, mapping)\n",
    "        word_encoded = one_hot_encoding(word_int, len(mapping))\n",
    "        result.append(word_encoded)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_list(array, mapping):\n",
    "    '''\n",
    "    array -- list of word_encoded elements, each of one has shape (k, n), k being the length of each word\n",
    "    mapping -- dictionary with integers as keys and characters as values\n",
    "    returns -> list of words'''\n",
    "    result = []\n",
    "    for word_encoded in array:\n",
    "        word_int = one_hot_decoding(word_encoded)\n",
    "        word = decode_int_to_word(word_int, mapping)\n",
    "        result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Map Data\n",
    "Load names and store them in **male_names_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_names_raw = pd.read_csv(MALE_NAMES_FILEPATH, sep = ';', decimal = ',')\n",
    "male_names_data = male_names_raw['Nombre'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the parameters of the model. Here, we have that **samples** are **names**, **inputs** are **characters or letters**,  **features** referes to the **number of characters**, and **timesteps** to the **length of a sample**, that is, the number of inputs in a sample.  \n",
    "`m:` number of samples  \n",
    "`n:` number of features, vocabulary size  \n",
    "`timesteps:` each sample has a different number of timesteps. For computation purposes, we set this to the **maximum length of the samples**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(male_names_data)\n",
    "n = len(map_char_to_int)\n",
    "timesteps = len(max(male_names_data, key = len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranform everything to **lowercase**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_names_data = [x.lower() for x in male_names_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create matrices $X$ and $y$. At every timestep, we will want our network to predict which is the letter for this timestep. We obviously want it to predict too when the name finishes, which will be indicated by a dot. Then, $y$ is just $X$ shifted one position to the right and with a dot added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some input examples:\n",
      "['antonio', 'jose', 'manuel']\n",
      "\n",
      "The outputs for the examples above:\n",
      "['ntonio.', 'ose.', 'anuel.']\n"
     ]
    }
   ],
   "source": [
    "X_male = male_names_data\n",
    "y_male = [name[1:] + '.' for name in X_male]\n",
    "\n",
    "print(\"Some input examples:\")\n",
    "print(X_male[:3])\n",
    "print(\"\\nThe outputs for the examples above:\")\n",
    "print(y_male[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each letter will be encoded as an integer, which in turn, will be one-hot encoded. For example:  \n",
    "\n",
    "$$ carlos \\rightarrow [2, 0, 17, 11, 14, 18] \\rightarrow [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [...], ..., [...]]$$\n",
    "\n",
    "Remember that the first representation we name it with `_int`, and the second with `_encoded`. Let's store both representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_male_int = []\n",
    "X_male_encoded = []\n",
    "\n",
    "for i in range(m):\n",
    "    word = X_male[i]\n",
    "    \n",
    "    word_int = encode_word_to_int(word, map_char_to_int)\n",
    "    X_male_int.append(word_int)\n",
    "    \n",
    "    word_encoded = one_hot_encoding(word_int, n)\n",
    "    X_male_encoded.append(word_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Antonio mapped to integer:\n",
      "[ 0 13 19 14 13  8 14]\n",
      "\n",
      "Previous integers one-hot encoded, which represent Antonio one-hot-encoded:\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Show some examples\n",
    "print(f\"Name Antonio mapped to integer:\\n{X_male_int[0]}\")\n",
    "print(f\"\\nPrevious integers one-hot encoded, which represent Antonio one-hot-encoded:\\n{X_male_encoded[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the labels, we could have computed them above in the same loop, but let's just use a different way: given that we already have the integers and one-hot encoded representations of each name, we just have to **shift** them one position forward and add the **mapping of the dot**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_encoded = one_hot_encoding([map_char_to_int['.']], n)\n",
    "y_male_int = [word_int[1:] + [map_char_to_int['.']] for word_int in X_male_int]\n",
    "y_male_encoded = [np.concatenate((l[1:], dot_encoded), axis = 0)for l in X_male_encoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding\n",
    "The fact that names have different sizes is something that needs to be addressed for computation purposes. The inputs of our model consist of single characters, but each of them form a word, whose length is the number of timesteps. When applying a batch optimization algorithm, it is required that all the samples have the same number of timesteps.\n",
    "\n",
    "There are several approaches to tackle the fact that samples have different lengths, we are going to use **padding** and **masking**. \n",
    "\n",
    "1. Padding adds characters to the sample so they all have the same length (the length of the longest one will do). We have computed this number at the beginning and named it `timesteps`. TensorFlow provides a built-in function that performs this padding. We are going to pad using 0s, that is, **adding** as many **zero-arrays** of shape (n,) as necessary to each sample.\n",
    "\n",
    "2. Masking refers to the fact of specifying that an input value **should not be considered**, since it is padding. Keras implements this with a layer, which has a `mask_value` parameter: when all the input features are equal to this mask_value, that timestep is ignored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = np.zeros(n, dtype = 'int')\n",
    "X_male_padded = tf.keras.preprocessing.sequence.pad_sequences(X_male_encoded,\n",
    "                                                            maxlen = timesteps,\n",
    "                                                            padding = 'post',\n",
    "                                                            truncating = 'post', \n",
    "                                                            value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_male_padded = tf.keras.preprocessing.sequence.pad_sequences(y_male_encoded,\n",
    "                                                       maxlen = timesteps,\n",
    "                                                       padding = 'post',\n",
    "                                                       truncating = 'post', \n",
    "                                                       value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_male_input = X_male_padded\n",
    "y_male_input = y_male_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "We are going to use a very simple RNN, which is known as the **Elman Network**. There is not a built-in layer for this network, but it is not difficult to build. At each timestep, the Elman Network computes:\n",
    "\n",
    "$$a_t = \\sigma_a(W_x x_t + W_a a_{t-1} + b_a)$$\n",
    "$$y_t = \\sigma_y(W_y a_t + b_y)$$\n",
    "\n",
    "Where:  \n",
    "$W_x, W_a, b_a; W_y, b_y$ are the parameters that the network has to learn, and do not depend on the timestep.  \n",
    "$\\sigma_a, \\sigma_y$ are activation functions, and are hyperparameters of the model. \n",
    "\n",
    "1. As discussed in the padding section, the `Masking` layer ignores all timesteps whose values are all 0s. \n",
    "2. Computing $a_t$ is done by the `SimpleRNN`layer, whose output is $a_t$. When `return_sequences` is set to `True`, it returns $\\{a_0, a_1, ..., a_t\\}$, instead of just $a_t$. We need this for the following layer:\n",
    "3. If at each timestep $t$, the output $y$ was computed using all activations $\\{a_0, a_1, ..., a_t\\}$, it would be as simple as adding a usual Dense layer. However, at each timestep, we must consider only the output of the current timestep. This is done by the wrapping `TimeDistributed`.\n",
    "\n",
    "*Remarks*:   \n",
    "1. `input_shape` has the form `(timesteps, features)`. Later on, we will need to predict using unpadded samples of different lengths, so it must be set to `None`.\n",
    "2. The number of **units** is a hyperparameter of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTION 1: define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(Masking(input_shape = (None, n),\n",
    "                  mask_value = 0))\n",
    "model.add(SimpleRNN(units = 100,\n",
    "                   return_sequences = True,\n",
    "                   activation = 'tanh'))\n",
    "model.add(TimeDistributed(Dense(units = n,\n",
    "                               activation = 'softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_male_input, y_male_input, epochs = 60)\n",
    "model.save(os.path.join(OUTPUT_PATH, 'model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: load an existing trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, None, 39)          0         \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, None, 100)         14000     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 39)          3939      \n",
      "=================================================================\n",
      "Total params: 17,939\n",
      "Trainable params: 17,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(os.path.join(OUTPUT_PATH, 'model.h5'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 96us/sample - loss: 0.3788 - accuracy: 0.7474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3787724329471588, 0.7473625]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_male_input, y_male_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "Let's check how good our algorithm performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_encoded = model.predict(X_male_input)\n",
    "y_preds = np.array(decode_list(y_preds_encoded, map_int_to_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare some predictions with the original labels. We must consider that the original labels have different lengths, and our model predicts for a fixed number of timesteps. Considering that our dot (.) is our EOF, **everything that comes after should not be considered**. A correct prediction though should end with a dot, like the original labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ntonio</td>\n",
       "      <td>ntonio.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ose</td>\n",
       "      <td>ose.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anuel</td>\n",
       "      <td>anuel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rancisco</td>\n",
       "      <td>rancisco.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anid</td>\n",
       "      <td>avid.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>rrerico jarlos.......</td>\n",
       "      <td>ederico carlos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>rrnando anrusto......</td>\n",
       "      <td>ernando augusto.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>urardo jrancisco.....</td>\n",
       "      <td>erardo francisco.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>ensai................</td>\n",
       "      <td>ossam.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>saael jrancisco......</td>\n",
       "      <td>smael francisco.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Prediction           Original\n",
       "0     ntonio                           ntonio.\n",
       "1     ose                                 ose.\n",
       "2     anuel                             anuel.\n",
       "3     rancisco                       rancisco.\n",
       "4     anid                               avid.\n",
       "...                     ...                ...\n",
       "4995  rrerico jarlos.......    ederico carlos.\n",
       "4996  rrnando anrusto......   ernando augusto.\n",
       "4997  urardo jrancisco.....  erardo francisco.\n",
       "4998  ensai................             ossam.\n",
       "4999  saael jrancisco......   smael francisco.\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_correct_df = pd.DataFrame(zip(y_preds, y_male), columns = [\"Prediction\", \"Original\"])\n",
    "wrong_correct_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inputs are single characters, so every single character correctly predicted must be considered a **success**, regardless if the whole sample (name) has not been predicted correctly as a whole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_correct = []\n",
    "for i in range(m):\n",
    "    for j, c in enumerate(y_male[i]):\n",
    "        mask_correct.append(y_preds[i][j] == c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nevertheless, we can also compute those samples (names) that have been predicted correctly as a whole (in this case we have chosen not to consider the final dot). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['antonio', 'jose', 'manuel', 'francisco', 'jose antonio', 'daniel',\n",
       "       'carlos', 'pedro', 'luis', 'ramon', 'oscar', 'santiago', 'eduardo',\n",
       "       'victor', 'guillermo', 'tomas', 'hector', 'xavier', 'isaac',\n",
       "       'benito', 'antoni', 'pedro antonio', 'kevin', 'eduard',\n",
       "       'luis angel', 'manuel antonio', 'anton', 'carlos antonio', 'xavi',\n",
       "       'ulises', 'yassin', 'zakaria', 'victor jesus', 'ramon antonio',\n",
       "       'dani', 'daniel antonio', 'fran', 'eduardo jesus', 'dan', 'santi',\n",
       "       'carlo', 'tomas antonio', 'guillermo jesus', 'benito jose', 'manu',\n",
       "       'kevin jesus', 'francis', 'oscar alejandro', 'franc',\n",
       "       'francisco alexis', 'santiago angel', 'quirino', 'tom', 'willian',\n",
       "       'isaac jesus', 'edu', 'hector juan'], dtype='<U21')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_correct_words = np.array([False] * m)\n",
    "for i in range(m):\n",
    "    pred = y_preds[i]\n",
    "    orig = y_male[i][:-1]  # do not consider the final dot\n",
    "    mask_correct_words[i] = orig in pred\n",
    "    \n",
    "correct_preds = np.array(X_male)[mask_correct_words]\n",
    "correct_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute **Accuracy**. We can also compute the accuracy over words, that is, how many names are predicted correctly as a whole. We can see that this way the accuracy plummets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (single characters as inputs)\n",
      "0.7474\n",
      "\n",
      "Accuracy over words\n",
      "0.0114\n"
     ]
    }
   ],
   "source": [
    "acc = sum(mask_correct)/len(mask_correct)\n",
    "acc_words = sum(mask_correct_words)/len(mask_correct_words)\n",
    "\n",
    "print(\"Accuracy (single characters as inputs)\")\n",
    "print(\"{:.4f}\".format(acc))\n",
    "print(\"\\nAccuracy over words\")\n",
    "print(acc_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation\n",
    "The way we can generate text with a neural network trained like this is as follows; let's show it with an example:\n",
    "\n",
    "If we chose a random letter, let's say *a*, and feed it to the network, we will obtain an output vector of shape `n`. These are the probabilities of each character being the second one considering that *a* is the first one.  \n",
    "Remembering that each position $1...n$ represents a character, what we can do now is chose a number $i$ with a probability $y_i$. Let's say we get integer *13*, which corresponds to letter *n*. Now, we feed our model with *an* as input, and get the next output. We keep going until we obtain a dot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 161 calls to <function _make_execution_function.<locals>.distributed_function at 0x0000012233A061F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 162 calls to <function _make_execution_function.<locals>.distributed_function at 0x0000012233A061F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 163 calls to <function _make_execution_function.<locals>.distributed_function at 0x0000012233A061F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 164 calls to <function _make_execution_function.<locals>.distributed_function at 0x0000012233A061F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 165 calls to <function _make_execution_function.<locals>.distributed_function at 0x0000012233A061F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 166 calls to <function _make_execution_function.<locals>.distributed_function at 0x0000012233A061F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 167 calls to <function _make_execution_function.<locals>.distributed_function at 0x0000012233A061F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function _make_execution_function.<locals>.distributed_function at 0x0000012233A061F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function _make_execution_function.<locals>.distributed_function at 0x0000012233A061F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "pedro jesus.\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((1, 1, n))\n",
    "word = ''\n",
    "c = '-'\n",
    "while c != '.':\n",
    "    y = model.predict(x)\n",
    "    y_n = y[0, -1, :]\n",
    "    y_n_hat = np.random.choice(range(n), p = y_n)\n",
    "    y_n_hat_encoded = np.reshape(one_hot_encoding([y_n_hat], n), (1, 1, -1))\n",
    "    \n",
    "    c = map_int_to_char[y_n_hat]\n",
    "    word += c\n",
    "    x = np.concatenate((x, y_n_hat_encoded), axis = 1)\n",
    "    \n",
    "print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take the most likely output at each timestep instead of chosing the output weighted by probability, we will get the **most likely name**, which is not subject to any randomness. With our model, and with no first letter given, **Eduardo Jesus** is the most likely name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eduardo jesus.\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((1, 1, n))\n",
    "word = ''\n",
    "c = '-'\n",
    "while c != '.':\n",
    "    y = model.predict(x)\n",
    "    y_n = y[0, -1, :]\n",
    "    y_n_hat = np.argmax(y_n)\n",
    "    y_n_hat_encoded = np.reshape(one_hot_encoding([y_n_hat], n), (1, 1, -1))\n",
    "    \n",
    "    c = map_int_to_char[y_n_hat]\n",
    "    word += c\n",
    "    x = np.concatenate((x, y_n_hat_encoded), axis = 1)\n",
    "    \n",
    "print(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
