{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SimpleRNN, TimeDistributed, Dense, Masking\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'\n",
    "OUTPUT_PATH = '../output'\n",
    "\n",
    "MALE_NAMES_FILEPATH = '../data/male_names.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mappings **map_char_to_int** and **map_int_to_char**, which map a character to its integer representation and viceversa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_chars = [chr(i) for i in range(97, 123)]\n",
    "special_chars = [' ', 'à', 'á', 'è', 'é', 'í', 'ò', 'ó', 'ú', 'ñ', 'ç', '.',\"'\",]\n",
    "chars = standard_chars + special_chars\n",
    "\n",
    "seq = [i for i in range(1, len(chars) + 1)]  # They start at 1\n",
    "map_char_to_int = dict(zip(chars, seq))\n",
    "map_int_to_char = dict(zip(seq, chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(encoded_array, features):\n",
    "    n = len(encoded_array)\n",
    "    results = np.zeros((n, features), dtype = 'int8')\n",
    "    for i in range(n):\n",
    "        pos = encoded_array[i]\n",
    "        results[i, pos - 1] = 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_decoding(decoded_array):\n",
    "    # Shape: (timesteps, n)\n",
    "    a, b = decoded_array.shape\n",
    "    results = np.zeros(a, dtype = 'int32')\n",
    "    for i in range(a):\n",
    "        pos = np.argmax(decoded_array[i])\n",
    "        results[i] = pos + 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_word_to_int(word, mapping):\n",
    "    n = len(word)\n",
    "    result = np.zeros(n, dtype = 'int32')\n",
    "    for i, c in enumerate(word):\n",
    "        result[i] = mapping[c]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_int_to_word(word_int, mapping):\n",
    "    n = len(word_int)\n",
    "    result = ''\n",
    "    for i in word_int:\n",
    "        if i in mapping.keys():\n",
    "            result += mapping[i]\n",
    "        else:\n",
    "            result += 'UNK'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_list(array, mapping):\n",
    "    result = []\n",
    "    for word in array:\n",
    "        word_int = encode_word_to_int(word, mapping)\n",
    "        word_encoded = one_hot_encoding(word_int, len(mapping))\n",
    "        result.append(word_encoded)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_list(array, mapping):\n",
    "    result = []\n",
    "    for word_encoded in array:\n",
    "        word_int = one_hot_decoding(word_encoded)\n",
    "        word = decode_int_to_word(word_int, mapping)\n",
    "        result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load names and store them in **male_names_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_names_raw = pd.read_csv(MALE_NAMES_FILEPATH, sep = ';', decimal = ',')\n",
    "male_names_data = male_names_raw['Nombre'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the parameters of the model:  \n",
    "`m:` number of samples  \n",
    "`n:` number of features  \n",
    "`timesteps:` length of the input vector. Since names have different lenghts, we will have to pad them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(male_names_data)\n",
    "n = len(map_char_to_int)\n",
    "timesteps = len(max(male_names_data, key = len))  # We will add a dot later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranform everything to **lowercase**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_names_data = [x.lower() for x in male_names_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create matrices $X$ and $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_male = male_names_data\n",
    "y_male = [name[1:] + '.' for name in X_male]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each letter will be encoded as an integer, which in turn, will be one-hot encoded. For example:  \n",
    "\n",
    "$$ carlos \\rightarrow [2, 0, 17, 11, 14, 18] \\rightarrow [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [...], ..., [...]]$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_male_int = []\n",
    "X_male_encoded = []\n",
    "for i in range(m):\n",
    "    word = X_male[i]\n",
    "    mapped_word = list(map(lambda x: map_char_to_int[x], word))  # Word as a list of integers representing letters\n",
    "    X_male_int.append(mapped_word)\n",
    "    \n",
    "    mapped_word = one_hot_encoding(mapped_word, n)  # 2D array with integers one-hot encoded\n",
    "    X_male_encoded.append(mapped_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Antonio mapped to integer:\n",
      "[1, 14, 20, 15, 14, 9, 15]\n",
      "\n",
      "Previous integers one-hot encoded:\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Show some examples\n",
    "print(f\"Name Antonio mapped to integer:\\n{X_male_int[0]}\")\n",
    "print(f\"\\nPrevious integers one-hot encoded:\\n{X_male_encoded[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the **labels**, they are the same as the inputs shifted one character forward, and adding a final **EOF** character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_encoded = one_hot_encoding([map_char_to_int['.']], n)\n",
    "y_male_int = [word_int[1:] + [map_char_to_int['.']] for word_int in X_male_int]\n",
    "y_male_encoded = [np.concatenate((l[1:], dot_encoded), axis = 0)for l in X_male_encoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some **padding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = np.zeros(n, dtype = 'int')\n",
    "X_male_padded = tf.keras.preprocessing.sequence.pad_sequences(X_male_encoded,\n",
    "                                                            maxlen = timesteps,\n",
    "                                                            padding = 'post',\n",
    "                                                            truncating = 'post', \n",
    "                                                            value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_male_padded = tf.keras.preprocessing.sequence.pad_sequences(y_male_encoded,\n",
    "                                                       maxlen = timesteps,\n",
    "                                                       padding = 'post',\n",
    "                                                       truncating = 'post', \n",
    "                                                       value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_male_input = X_male_padded\n",
    "y_male_input = y_male_padded\n",
    "# X_male_input = np.array(X_male, dtype = 'float32')\n",
    "# y_male_input = np.array(y_male, dtype = 'float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(Masking(input_shape = (None, n),\n",
    "                  mask_value = 0))\n",
    "model.add(SimpleRNN(units = 100,\n",
    "                   return_sequences = True,\n",
    "                   activation = 'tanh'))\n",
    "model.add(TimeDistributed(Dense(units = n,\n",
    "                               activation = 'softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, None, 39)          0         \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, None, 100)         14000     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 39)          3939      \n",
      "=================================================================\n",
      "Total params: 17,939\n",
      "Trainable params: 17,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples\n",
      "Epoch 1/60\n",
      "5000/5000 [==============================] - 1s 279us/sample - loss: 1.3208 - accuracy: 0.2563\n",
      "Epoch 2/60\n",
      "5000/5000 [==============================] - 1s 162us/sample - loss: 0.9880 - accuracy: 0.4289\n",
      "Epoch 3/60\n",
      "5000/5000 [==============================] - 1s 150us/sample - loss: 0.8560 - accuracy: 0.5002\n",
      "Epoch 4/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.7852 - accuracy: 0.5374\n",
      "Epoch 5/60\n",
      "5000/5000 [==============================] - 1s 145us/sample - loss: 0.7410 - accuracy: 0.5667\n",
      "Epoch 6/60\n",
      "5000/5000 [==============================] - 1s 150us/sample - loss: 0.7084 - accuracy: 0.5850\n",
      "Epoch 7/60\n",
      "5000/5000 [==============================] - 1s 146us/sample - loss: 0.6830 - accuracy: 0.5977\n",
      "Epoch 8/60\n",
      "5000/5000 [==============================] - 1s 147us/sample - loss: 0.6628 - accuracy: 0.6091\n",
      "Epoch 9/60\n",
      "5000/5000 [==============================] - 1s 146us/sample - loss: 0.6468 - accuracy: 0.6148\n",
      "Epoch 10/60\n",
      "5000/5000 [==============================] - 1s 146us/sample - loss: 0.6315 - accuracy: 0.6239\n",
      "Epoch 11/60\n",
      "5000/5000 [==============================] - 1s 147us/sample - loss: 0.6184 - accuracy: 0.6318\n",
      "Epoch 12/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.6074 - accuracy: 0.6364\n",
      "Epoch 13/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.5975 - accuracy: 0.6407\n",
      "Epoch 14/60\n",
      "5000/5000 [==============================] - 1s 148us/sample - loss: 0.5881 - accuracy: 0.6465\n",
      "Epoch 15/60\n",
      "5000/5000 [==============================] - 1s 147us/sample - loss: 0.5784 - accuracy: 0.6523\n",
      "Epoch 16/60\n",
      "5000/5000 [==============================] - 1s 148us/sample - loss: 0.5712 - accuracy: 0.6565\n",
      "Epoch 17/60\n",
      "5000/5000 [==============================] - 1s 147us/sample - loss: 0.5638 - accuracy: 0.6580\n",
      "Epoch 18/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.5569 - accuracy: 0.6643\n",
      "Epoch 19/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.5508 - accuracy: 0.6657\n",
      "Epoch 20/60\n",
      "5000/5000 [==============================] - 1s 148us/sample - loss: 0.5450 - accuracy: 0.6688\n",
      "Epoch 21/60\n",
      "5000/5000 [==============================] - 1s 150us/sample - loss: 0.5388 - accuracy: 0.6716\n",
      "Epoch 22/60\n",
      "5000/5000 [==============================] - 1s 148us/sample - loss: 0.5338 - accuracy: 0.6723\n",
      "Epoch 23/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.5293 - accuracy: 0.6754\n",
      "Epoch 24/60\n",
      "5000/5000 [==============================] - 1s 152us/sample - loss: 0.5238 - accuracy: 0.6786\n",
      "Epoch 25/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.5196 - accuracy: 0.6811\n",
      "Epoch 26/60\n",
      "5000/5000 [==============================] - 1s 150us/sample - loss: 0.5155 - accuracy: 0.6823\n",
      "Epoch 27/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.5111 - accuracy: 0.6849\n",
      "Epoch 28/60\n",
      "5000/5000 [==============================] - 1s 148us/sample - loss: 0.5077 - accuracy: 0.6851\n",
      "Epoch 29/60\n",
      "5000/5000 [==============================] - 1s 148us/sample - loss: 0.5043 - accuracy: 0.6875\n",
      "Epoch 30/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.5007 - accuracy: 0.6889\n",
      "Epoch 31/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.4967 - accuracy: 0.6909\n",
      "Epoch 32/60\n",
      "5000/5000 [==============================] - 1s 153us/sample - loss: 0.4944 - accuracy: 0.6927\n",
      "Epoch 33/60\n",
      "5000/5000 [==============================] - 1s 150us/sample - loss: 0.4917 - accuracy: 0.6925\n",
      "Epoch 34/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.4879 - accuracy: 0.6941\n",
      "Epoch 35/60\n",
      "5000/5000 [==============================] - 1s 150us/sample - loss: 0.4850 - accuracy: 0.6956\n",
      "Epoch 36/60\n",
      "5000/5000 [==============================] - 1s 148us/sample - loss: 0.4824 - accuracy: 0.6971\n",
      "Epoch 37/60\n",
      "5000/5000 [==============================] - 1s 148us/sample - loss: 0.4806 - accuracy: 0.6972\n",
      "Epoch 38/60\n",
      "5000/5000 [==============================] - 1s 148us/sample - loss: 0.4775 - accuracy: 0.6998\n",
      "Epoch 39/60\n",
      "5000/5000 [==============================] - 1s 148us/sample - loss: 0.4741 - accuracy: 0.7012\n",
      "Epoch 40/60\n",
      "5000/5000 [==============================] - 1s 148us/sample - loss: 0.4717 - accuracy: 0.7031\n",
      "Epoch 41/60\n",
      "5000/5000 [==============================] - 1s 148us/sample - loss: 0.4697 - accuracy: 0.7026\n",
      "Epoch 42/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.4673 - accuracy: 0.7044\n",
      "Epoch 43/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.4655 - accuracy: 0.7059\n",
      "Epoch 44/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.4631 - accuracy: 0.7058\n",
      "Epoch 45/60\n",
      "5000/5000 [==============================] - 1s 150us/sample - loss: 0.4611 - accuracy: 0.7074\n",
      "Epoch 46/60\n",
      "5000/5000 [==============================] - 1s 148us/sample - loss: 0.4590 - accuracy: 0.7071\n",
      "Epoch 47/60\n",
      "5000/5000 [==============================] - 1s 148us/sample - loss: 0.4568 - accuracy: 0.7087\n",
      "Epoch 48/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.4546 - accuracy: 0.7091\n",
      "Epoch 49/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.4531 - accuracy: 0.7095\n",
      "Epoch 50/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.4509 - accuracy: 0.7108\n",
      "Epoch 51/60\n",
      "5000/5000 [==============================] - 1s 152us/sample - loss: 0.4494 - accuracy: 0.7111\n",
      "Epoch 52/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.4478 - accuracy: 0.7131\n",
      "Epoch 53/60\n",
      "5000/5000 [==============================] - 1s 150us/sample - loss: 0.4459 - accuracy: 0.7136\n",
      "Epoch 54/60\n",
      "5000/5000 [==============================] - 1s 155us/sample - loss: 0.4451 - accuracy: 0.7127\n",
      "Epoch 55/60\n",
      "5000/5000 [==============================] - 1s 151us/sample - loss: 0.4434 - accuracy: 0.7149\n",
      "Epoch 56/60\n",
      "5000/5000 [==============================] - 1s 152us/sample - loss: 0.4411 - accuracy: 0.7148\n",
      "Epoch 57/60\n",
      "5000/5000 [==============================] - 1s 152us/sample - loss: 0.4398 - accuracy: 0.7156\n",
      "Epoch 58/60\n",
      "5000/5000 [==============================] - 1s 150us/sample - loss: 0.4388 - accuracy: 0.7167\n",
      "Epoch 59/60\n",
      "5000/5000 [==============================] - 1s 151us/sample - loss: 0.4369 - accuracy: 0.7166\n",
      "Epoch 60/60\n",
      "5000/5000 [==============================] - 1s 149us/sample - loss: 0.4369 - accuracy: 0.7166\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_male_input, y_male_input, epochs = 60)\n",
    "# model = load_model(os.path.join(OUTPUT_PATH, 'model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(OUTPUT_PATH, 'model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 93us/sample - loss: 0.4271 - accuracy: 0.7236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42711880807876584, 0.7236106]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_male_input, y_male_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_male_input)\n",
    "preds_decoded = np.array(decode_list(preds, map_int_to_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ntonio</td>\n",
       "      <td>ntonio.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ose</td>\n",
       "      <td>ose.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aruel</td>\n",
       "      <td>anuel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rancisco</td>\n",
       "      <td>rancisco.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avid</td>\n",
       "      <td>avid.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>rlerico jarlos.......</td>\n",
       "      <td>ederico carlos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>rlnando alresto......</td>\n",
       "      <td>ernando augusto.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>urardo jrancisco.....</td>\n",
       "      <td>erardo francisco.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>ertai................</td>\n",
       "      <td>ossam.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>saael jrancisco......</td>\n",
       "      <td>smael francisco.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Prediction           Original\n",
       "0     ntonio                           ntonio.\n",
       "1     ose                                 ose.\n",
       "2     aruel                             anuel.\n",
       "3     rancisco                       rancisco.\n",
       "4     avid                               avid.\n",
       "...                     ...                ...\n",
       "4995  rlerico jarlos.......    ederico carlos.\n",
       "4996  rlnando alresto......   ernando augusto.\n",
       "4997  urardo jrancisco.....  erardo francisco.\n",
       "4998  ertai................             ossam.\n",
       "4999  saael jrancisco......   smael francisco.\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_correct_df = pd.DataFrame(zip(preds_decoded, y_male), columns = [\"Prediction\", \"Original\"])\n",
    "wrong_correct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_correct_w_stop = []\n",
    "mask_correct_wo_stop = []\n",
    "for i in range(m):\n",
    "    for j, c in enumerate(y_male[i]):\n",
    "        mask_correct_w_stop.append(preds_decoded[i][j] == c)\n",
    "        mask_correct_wo_stop.append(preds_decoded[i][j] == c)\n",
    "        if c == '.':\n",
    "            mask_correct_wo_stop[-1] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['antonio', 'jose', 'francisco', 'david', 'carlos', 'rafael',\n",
       "       'pablo', 'luis', 'oscar', 'santiago', 'eduardo', 'victor',\n",
       "       'marcos', 'guillermo', 'marc', 'tomas', 'hector', 'xavier',\n",
       "       'isaac', 'bernardo', 'marco', 'antoni', 'kevin', 'eduard', 'anton',\n",
       "       'xavi', 'guillermo jose', 'fran', 'eduardo antonio', 'santi',\n",
       "       'bernardo jose', 'jose alexis', 'rafael alejandro', 'carlo',\n",
       "       'rafa', 'tomas antonio', 'santiago antonio', 'david alexander',\n",
       "       'francis', 'hector antonio', 'franc', 'kevin alejandro',\n",
       "       'carlos alexis', 'francisco alexis', 'isaac jose', 'bernard',\n",
       "       'quirino', 'antonio alexis', 'tom', 'luis alexis', 'edu',\n",
       "       'victor alexander'], dtype='<U21')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get words predicted correctly as a whole\n",
    "\n",
    "mask_correct_words = np.array([False] * m)\n",
    "for i in range(m):\n",
    "    pred = preds_decoded[i]\n",
    "    orig = y_male[i][:-1]\n",
    "    mask_correct_words[i] = orig in pred\n",
    "    \n",
    "correct_preds = np.array(X_male)[mask_correct_words]\n",
    "correct_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7236106002826226"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "sum(mask_correct_w_stop)/len(mask_correct_w_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "Randomly predict names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "òuritz.\n"
     ]
    }
   ],
   "source": [
    "# Text generation\n",
    "x = np.zeros((1, 1, n))\n",
    "word = ''\n",
    "c = '-'\n",
    "while c != '.':\n",
    "    y = model.predict(x)\n",
    "    y_n = y[0, -1, :]\n",
    "    y_n_hat = np.random.choice(range(1, n + 1), p = y_n)  # Canviar si es canvia n\n",
    "    y_n_hat_encoded = np.reshape(one_hot_encoding([y_n_hat], n), (1, 1, -1))\n",
    "    \n",
    "    c = map_int_to_char[y_n_hat]\n",
    "    word += c\n",
    "    x = np.concatenate((x, y_n_hat_encoded), axis = 1)\n",
    "print(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
